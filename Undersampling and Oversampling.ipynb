{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from time import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from preprocessing import DataHandler\n",
    "from models import Model\n",
    "\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_curve, auc, accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
    "\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "\n",
    "# import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = './parameters.json'\n",
    "with open(filename) as f:\n",
    "    parameters_data = json.load(f)\n",
    "\n",
    "seed, data_config, model_config = [parameters_data[key] for key in parameters_data.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column Rankings:\n",
    "# ('ALCOHOL', 1400)\n",
    "# ('SULPHATES', 1249)\n",
    "# ('VOLATILE_ACIDITY', 1111)\n",
    "# ('CITRIC_ACID', 1000)\n",
    "# ('TOTAL_SULFUR_DIOXIDE', 769)\n",
    "# ('FIXED_ACIDITY', 747)\n",
    "# ('CHLORIDES', 542)\n",
    "# ('DENSITY', 454)\n",
    "# ('RESIDUAL_SUGAR', 209)\n",
    "# ('pH', 206)\n",
    "# ('FREE_SULFUR_DIOXIDE', 13)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('dataset/winequality-red.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quality_binarize = [1 if row_quality in data_config['to_predict'] else 0 for row_quality in df[data_config['target']]]\n",
    "df[data_config['target']] = quality_binarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_data = DataHandler(random_state = seed)\n",
    "\n",
    "wine_data.load_data(df, data_config['features'], data_config['target'])\n",
    "wine_data.split_dataset(cross_validation_size = data_config['cv_size'],\n",
    "                        test_size = data_config['test_size'])\n",
    "\n",
    "print(wine_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rate_keep = 1.0\n",
    "subset_index = np.random.choice(wine_data.X_train.index,\n",
    "                                size = int(len(wine_data.X_train.index) * train_rate_keep),\n",
    "                                replace = False)\n",
    "\n",
    "training_set_subset = df.iloc[subset_index]\n",
    "X_train_subset = training_set_subset[data_config['features']]\n",
    "y_train_subset = training_set_subset[data_config['target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_cnt = list(y_train_subset).count(1)\n",
    "k_neighbors = 5 if positive_cnt >= 5 else positive_cnt\n",
    "# print(k_neighbors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_resampled, y_resampled = SMOTE(random_state = seed,\n",
    "                                 k_neighbors = k_neighbors\n",
    "                                 ,\n",
    "                                 sampling_strategy = 0.5\n",
    "                                ).fit_resample(X_train_subset, y_train_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.unique(wine_data.y_train, return_counts = True))\n",
    "print(np.unique(wine_data.y_cross_validation, return_counts = True))\n",
    "print(np.unique(wine_data.y_test, return_counts = True))\n",
    "print(np.unique(y_resampled, return_counts = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = StratifiedKFold(n_splits = data_config['k_folds'], shuffle = True, random_state = seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "models_scores = []\n",
    "tensorboards = [\n",
    "    tf.keras.callbacks.TensorBoard(log_dir=\"logs/resampled/{}\".format(time())),\n",
    "    tf.keras.callbacks.TensorBoard(log_dir=\"logs/vanilla/{}\".format(time()))\n",
    "]\n",
    "\n",
    "for t in tensorboards:\n",
    "    new_model = Model(tensorboard = t)\n",
    "    new_model.create(input_dim = wine_data.X_train.shape[1])\n",
    "    models.append(new_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(x_to_train, y_to_train, model=None):\n",
    "    \n",
    "    for training_index, cross_validation_index in kfold.split(x_to_train, y_to_train):\n",
    "        \n",
    "        if isinstance(x_to_train, pd.DataFrame):\n",
    "            x = x_to_train.values[training_index]\n",
    "            y = y_to_train.values[training_index]\n",
    "            cv = [x_to_train.values[cross_validation_index], y_to_train.values[cross_validation_index]]\n",
    "        else:\n",
    "            x = x_to_train[training_index]\n",
    "            y = y_to_train[training_index]\n",
    "            cv = [x_to_train[cross_validation_index], y_to_train[cross_validation_index]]\n",
    "        \n",
    "        print(x)\n",
    "        current_model = model.train(epochs = model_config['epochs_param'],\n",
    "    #                                     batch_size = model_config['batch_size'],\n",
    "                                        X_data = x, y_data = y,\n",
    "                                        validation_data = cv\n",
    "                                       )\n",
    "        print('End of Model Training')\n",
    "\n",
    "        current_model_predictions = model.model.predict(x = wine_data.X_test)\n",
    "\n",
    "        # Data Type, Training Data Accuracy, Cross Validation Accuracy, Test Accuracy, Precision, Recall, F1_score\n",
    "        models_scores.append([\n",
    "            'vanilla',\n",
    "            current_model.history['acc'][-1],\n",
    "            current_model.history['val_acc'][-1],\n",
    "            accuracy_score(wine_data.y_test, np.round(current_model_predictions)),\n",
    "            precision_score(wine_data.y_test, np.round(current_model_predictions)),\n",
    "            recall_score(wine_data.y_test, np.round(current_model_predictions)),\n",
    "            f1_score(wine_data.y_test, np.round(current_model_predictions)),\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(X_resampled, y_resampled, models[0])\n",
    "train_model(wine_data.X_train, wine_data.y_train, models[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_label = np.arange(1, data_config['k_folds'] + 1)\n",
    "index_label = np.tile(index_label, (2, 1))\n",
    "\n",
    "results_info = pd.DataFrame(data = models_scores,\n",
    "                            index = index_label,\n",
    "                            columns = ['Data Type',\n",
    "                                       'Training Accuracy', 'Cross Validation Accuracy','Test Accuracy',\n",
    "                                       'Precision', 'Recall', 'F1_Score']\n",
    "                           )\n",
    "results_info.index.name = 'KFold Iteration'\n",
    "results_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = [confusion_matrix(wine_data.y_test, np.round(pred)) for pred in predictions]\n",
    "\n",
    "fig, ax = plt.subplots(nrows = 1, ncols = 2, figsize = (14, 6), dpi = 100)\n",
    "sns.heatmap(cm[0], annot = True, fmt = 'd', ax = ax[0])\n",
    "ax[0].set_title('Upsampling')\n",
    "ax[0].set_xlabel('Predicted Label')\n",
    "ax[0].set_ylabel('True Label')\n",
    "\n",
    "sns.heatmap(cm[1], annot = True, fmt = 'd', ax = ax[1])\n",
    "ax[1].set_title('Vanilla')\n",
    "ax[1].set_xlabel('Predicted Label')\n",
    "ax[1].set_ylabel('True Label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr = []\n",
    "tpr = []\n",
    "roc_auc = []\n",
    "\n",
    "for pred in predictions:\n",
    "    \n",
    "    current_fpr, current_tpr, _ = roc_curve(wine_data.y_test, pred)\n",
    "    current_roc_auc = auc(current_fpr, current_tpr)\n",
    "    \n",
    "    fpr.append(current_fpr)\n",
    "    tpr.append(current_tpr)\n",
    "    roc_auc.append(current_roc_auc)\n",
    "    \n",
    "fig, ax = plt.subplots(nrows = 1, ncols = 2, figsize = (14, 6), dpi = 100)\n",
    "ax[0].set_title('Receiver Operating Characteristic Upsampling')\n",
    "ax[0].plot(fpr[0], tpr[0], 'b', label = 'ROC curve (area = %0.2f)' % roc_auc[0])\n",
    "ax[0].legend(loc = 'lower right')\n",
    "ax[0].plot([0, 1], [0, 1],'r--')\n",
    "ax[0].set_xlim([0, 1])\n",
    "ax[0].set_ylim([0, 1])\n",
    "ax[0].set_ylabel('True Positive Rate')\n",
    "ax[0].set_xlabel('False Positive Rate')\n",
    "\n",
    "ax[1].set_title('Receiver Operating Characteristic Vanilla')\n",
    "ax[1].plot(fpr[1], tpr[1], 'b', label = 'ROC curve (area = %0.2f)' % roc_auc[1])\n",
    "ax[1].legend(loc = 'lower right')\n",
    "ax[1].plot([0, 1], [0, 1],'r--')\n",
    "ax[1].set_xlim([0, 1])\n",
    "ax[1].set_ylim([0, 1])\n",
    "ax[1].set_ylabel('True Positive Rate')\n",
    "ax[1].set_xlabel('False Positive Rate')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fpr_vanilla = []\n",
    "# tpr_vanilla = []\n",
    "# roc_auc_vanilla = []\n",
    "# fpr_vanilla, tpr_vanilla, thresholds_vanilla = roc_curve(y_test, pred_vanilla)\n",
    "# roc_auc_vanilla = auc(fpr_vanilla, tpr_vanilla)\n",
    "\n",
    "# plt.title('Receiver Operating Characteristic')\n",
    "# plt.plot(fpr_vanilla, tpr_vanilla, 'b', label = 'ROC curve (area = %0.2f)' % roc_auc_vanilla)\n",
    "# plt.legend(loc = 'lower right')\n",
    "# plt.plot([0, 1], [0, 1],'r--')\n",
    "# plt.xlim([0, 1])\n",
    "# plt.ylim([0, 1])\n",
    "# plt.ylabel('True Positive Rate')\n",
    "# plt.xlabel('False Positive Rate')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# models_history = []\n",
    "# predictions = []\n",
    "# model_scores = []\n",
    "\n",
    "# for training_index, cross_validation_index in kfold.split(wine_data.X_train, wine_data.y_train):\n",
    "#     for itr, model in enumerate(models):\n",
    "#         data_for_training = training_data[itr][0]\n",
    "#         data_target = training_data[itr][1]\n",
    "#         current_model = model.fit(x = data_for_training[training_index], y = data_for_training[training_index],\n",
    "#                                   validation_data = (data_for_training[cross_validation_index], data_for_training[cross_validation_index]),\n",
    "#                                   batch_size = batch_size,\n",
    "#                                   class_weight = class_weight,\n",
    "#                                   epochs = epochs_param,\n",
    "#                                   shuffle = True,\n",
    "#                                   verbose = 2\n",
    "#     #                               ,callbacks = [tensorboards[itr]]\n",
    "#                                  )\n",
    "#         models_history.append(current_model)\n",
    "#         print('End of model training')\n",
    "\n",
    "#         current_model_predictions = model.predict(x = wine_data.X_test)\n",
    "#         predictions.append(current_model_predictions)\n",
    "\n",
    "#         # Data Type, Training Data Accuracy, Cross Validation Accuracy, Test Accuracy, Precision, Recall, F1_score\n",
    "#         model_scores.append([\n",
    "#             training_data[itr][2],\n",
    "#             current_model.history['acc'][-1],\n",
    "#             current_model.history['val_acc'][-1],\n",
    "#             accuracy_score(wine_data.y_test, np.round(current_model_predictions)),\n",
    "#             precision_score(wine_data.y_test, np.round(current_model_predictions)),\n",
    "#             recall_score(wine_data.y_test, np.round(current_model_predictions)),\n",
    "#             f1_score(wine_data.y_test, np.round(current_model_predictions)),\n",
    "#         ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.keras.backend.clear_session()\n",
    "# # tensorboards = [\n",
    "# #     tf.keras.callbacks.TensorBoard(log_dir=\"logs/resampled/{}\".format(time())),\n",
    "# #     tf.keras.callbacks.TensorBoard(log_dir=\"logs/vanilla/{}\".format(time()))\n",
    "# # ]\n",
    "\n",
    "# epochs_param = 50\n",
    "# input_dim = wine_data.X_train.shape[1]\n",
    "# # optimizer = tf.keras.optimizers.Adam(lr = 0.01)\n",
    "# optimizer = 'adam'\n",
    "# batch_size = 128\n",
    "# # class_weight = {0: 1, 1: 3}\n",
    "# class_weight = None\n",
    "\n",
    "# training_data = [\n",
    "#     [X_resampled, y_resampled, 'resampled']\n",
    "#     ,\n",
    "#     [wine_data.X_train, wine_data.y_train, 'vanilla']\n",
    "# ]\n",
    "\n",
    "models = []\n",
    "for _ in range(len(training_data)):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Dense(4, activation = tf.nn.elu, input_dim = input_dim, use_bias = True))\n",
    "#     model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.Dropout(rate = 0.2, seed = seed))\n",
    "    model.add(tf.keras.layers.Dense(4, activation = tf.nn.elu, use_bias = True))\n",
    "#     model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.Dropout(rate = 0.2, seed = seed))\n",
    "    model.add(tf.keras.layers.Dense(1, activation = tf.nn.sigmoid))\n",
    "    model.compile(optimizer = optimizer, loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index_numpy_array = np.array(df.index)\n",
    "# training_set_indices = np.random.choice(index_numpy_array,\n",
    "#                                         size = int(index_numpy_array.shape[0] * (1-test_size)),\n",
    "#                                         replace = False)\n",
    "\n",
    "# test_set_indices = np.delete(index_numpy_array, training_set_indices)\n",
    "# assert(len(df) == len(training_set_indices) + len(test_set_indices))\n",
    "\n",
    "# training_set = df.iloc[training_set_indices]\n",
    "# test_set = df.iloc[test_set_indices]\n",
    "\n",
    "# print(np.unique(training_set['QUALITY'], return_counts = True))\n",
    "# print(np.unique(test_set['QUALITY'], return_counts = True))\n",
    "\n",
    "# \"\"\"\n",
    "# Upsampling\n",
    "#     - since we have a data imbalance between wine qualities, perform upsampling to the minority class,\n",
    "#       so that the count between the qualities are the same\n",
    "#     - this is done by sampling from the minority class with replacement\n",
    "# \"\"\"\n",
    "# majority_size_pct = 0.3\n",
    "\n",
    "# full_training_set_majority_class = training_set[training_set['QUALITY'] != 1].index\n",
    "# full_training_set_minority_class = training_set[training_set['QUALITY'] == 1].index\n",
    "\n",
    "# upsampling_training_majority = np.random.choice(full_training_set_majority_class,\n",
    "#                                                size = int(len(full_training_set_majority_class) * majority_size_pct),\n",
    "#                                                replace = False\n",
    "#                                               )\n",
    "# upsampling_training_minority = np.random.choice(full_training_set_minority_class,\n",
    "#                                                size = int((len(full_training_set_majority_class) * majority_size_pct) * 1.0),\n",
    "#                                                replace = True\n",
    "#                                               )\n",
    "\n",
    "# upsampling_training_set = df.iloc[np.append(upsampling_training_majority, upsampling_training_minority)]\n",
    "# upsampling_cross_validation_set = training_set.drop(np.append(upsampling_training_majority, upsampling_training_minority))\n",
    "\n",
    "# # assert(len(training_set) == len(cross_validation_set_indices) + len(upsampled_training_majority) + len(upsampled_training_minority))\n",
    "\n",
    "# \"\"\"\n",
    "# Downsampling\n",
    "#     - since we have a data imbalance between wine qualities, perform Downsampling to the minority class,\n",
    "#       so that the count between the qualities are the same\n",
    "#     - this is done by subsampling from the majority class without replacement\n",
    "# \"\"\"\n",
    "\n",
    "# majority_size_pct = 0.3\n",
    "\n",
    "# full_training_set_majority_class = training_set[training_set['QUALITY'] != 1].index\n",
    "# full_training_set_minority_class = training_set[training_set['QUALITY'] == 1].index\n",
    "\n",
    "# upsampling_training_majority = np.random.choice(full_training_set_majority_class,\n",
    "#                                                size = len(full_training_set_minority_class) * 3,\n",
    "#                                                replace = False\n",
    "#                                               )\n",
    "# upsampling_training_minority = np.random.choice(full_training_set_minority_class,\n",
    "#                                                size = len(full_training_set_minority_class),\n",
    "#                                                replace = False\n",
    "#                                               )\n",
    "\n",
    "# upsampling_training_set = df.iloc[np.append(upsampling_training_majority, upsampling_training_minority)]\n",
    "# upsampling_cross_validation_set = training_set.drop(np.append(upsampling_training_majority, upsampling_training_minority))\n",
    "\n",
    "# # assert(len(training_set) == len(cross_validation_set_indices) + len(upsampled_training_majority) + len(upsampled_training_minority))\n",
    "\n",
    "# y_train = upsampling_training_set['QUALITY'].values\n",
    "# X_train = upsampling_training_set.drop(columns = ['QUALITY']).values\n",
    "\n",
    "# y_cross_validation = upsampling_cross_validation_set['QUALITY'].values\n",
    "# X_cross_validation = upsampling_cross_validation_set.drop(columns = ['QUALITY']).values\n",
    "\n",
    "# y_test = test_set['QUALITY'].values\n",
    "# X_test = test_set.drop(columns = ['QUALITY']).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = df[columns_to_choose]\n",
    "# y = df[target]\n",
    "#\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "#                                                     test_size = test_size,\n",
    "#                                                     random_state = seed\n",
    "#                                                    )\n",
    "# X_train, X_cross_validation, y_train, y_cross_validation = train_test_split(X_train, y_train,\n",
    "#                                                                             test_size = cross_validation_size,\n",
    "#                                                                             random_state = seed\n",
    "#                                                                            )\n",
    "#\n",
    "# sc = StandardScaler()\n",
    "# X_train = sc.fit_transform(X_train)\n",
    "# X_resampled = sc.fit_transform(X_resampled)\n",
    "# X_cross_validation = sc.fit_transform(X_cross_validation)\n",
    "# X_test = sc.fit_transform(X_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
